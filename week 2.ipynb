{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for Machine Learning class by by DeepLearning.AI & Stanford University\n",
    "## Week 2\n",
    "\n",
    "# Terminology\n",
    "\n",
    "| Definition        | Explanation            |\n",
    "|-------------------|------------------------|\n",
    "| *x<sub>j</sub>*| *j<sup>th</sup> feature|\n",
    "| *n* | total number of features|\n",
    "|*$\\overrightarrow{x}$* | A vector or feature of the all training example (the *optinal* arrow is to make clear this referce to a vector and not a single number| \n",
    "|*$\\overrightarrow{x}$ <sup>(i)</sup>* | A vector or feature of the *i<sup>th</sup>* training example (the *optinal* arrow is to make clear this referce to a vector and not a single number| \n",
    "|*x $_{j}^{(i)}$* | Value of feature *j* in *i<sup>th</sup>* training example|\n",
    "|*$\\overrightarrow{w}$*| Row vector with all the values for *w*|\n",
    "|*b*| single number|\n",
    "|*$\\overrightarrow{w}$* and *b* | parameters of the model|\n",
    "| dot product (e.g. $\\overrightarrow{w}$ $\\cdot$ $\\overrightarrow{x}$ ) | w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+...+w<sub>n</sub>x<sub>n</sub> |\n",
    "\n",
    "\n",
    "  \n",
    "# Multiple linear regression \n",
    "Whe you have one feature or variable, the function for a linear regression is *f<sub>w,b</sub> (x)=wx+b*. However, **when using mulitple features the formula is like this:**  \n",
    "*f<sub>w,b</sub> (x)=w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+...+w<sub>n</sub>x<sub>n</sub>+b*. A simpler way of writing it, implies using a dot product:  \n",
    "*$f$ <sub>$\\overrightarrow{w}$,b</sub>($\\overrightarrow{x}$)=$\\overrightarrow{w}$ $\\cdot$ $\\overrightarrow{x}$ + b*\n",
    "\n",
    "# Vectorization\n",
    "Without vectorization the formula would be ike this:  \n",
    "*f<sub>w,b</sub> (x)=w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+w<sub>3</sub>x<sub>3</sub>+b* which would be very slow to write and to compute. Without vectorization you can increase the speed by:  \n",
    "*$f$ <sub>$\\overrightarrow{w}$,b</sub>($\\overrightarrow{x}$)= $\\sum\\limits_{j=1}^{n}$ w<sub>j</sub>x<sub>j</sub> + b*.\n",
    "\n",
    "## Python vs algebra\n",
    "**Indexing**  \n",
    "In Python everything is 0 indexed wheras algebra (and Matlab) start at 1. This means for the vector $\\overrightarrow{w}$ = [w<sub>1</sub> w<sub>2</sub> w<sub>3</sub>] that in Python to get to the first parameter (w<sub>1</sub>), you would use w<sub>[0]</sub>  \n",
    "\n",
    "**Without vectorization** \n",
    "To run the formula  *f<sub>w,b</sub> (x)=w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+w<sub>3</sub>x<sub>3</sub>+b* you would need to type out:  \n",
    "```python\n",
    "f = w[0] * x[0] +  \n",
    "    w[1] * x[1] +  \n",
    "    w[2] * x[2] + b \n",
    "```\n",
    "This is not handy, quick or easy to compute. Because of that you can instead use this formula (as mentioned above): *$f$ <sub>$\\overrightarrow{w}$,b</sub>($\\overrightarrow{x}$)= $\\sum\\limits_{j=1}^{n}$ w<sub>j</sub>x<sub>j</sub> + b*. This translates to the following code:  \n",
    "\n",
    "```python\n",
    "f = 0  \n",
    "for j in range (0,n): #often writen range(n)\n",
    "    f = f + w[j] * x[j]\n",
    "f = f + b\n",
    "```\n",
    "This is better on the typing front, however it is still not the best, on the computational front. For that you need to use the dot prodcut or vectorization: *$f$ <sub>$\\overrightarrow{w}$,b</sub>($\\overrightarrow{x}$)=$\\overrightarrow{w}$ $\\cdot$ $\\overrightarrow{x}$ + b*. This translate to the following python code that requires the `numpy` library:  \n",
    "```python\n",
    "f = np.dot(w,x + b)\n",
    "``` \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba80823ec9edfa2b915b0e8b60f600e1ca4cb90dcbbf7f0d0e0246605aecf2a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
